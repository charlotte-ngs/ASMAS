---
title: "Multiple Lineare Regression (Teil 3)"
author: "Peter von Rohr"
date: "2 Mai 2016"
output: 
  beamer_presentation:
    fig_crop: no
    fig_height: 6
    fig_width: 10
    includes:
      in_header: tex/ethslidesheader.tex
    keep_tex: yes
documentclass: ETHbeamerclass
classoption: first,ETH3,navigation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Globaler Test eines Modells
- Beim t-Test hatten wir jede einzelne erklärende Variable getestet. 
- Test, ob überhaupt eine der erklärenden Variablen einen Einfluss auf die Zielgrösse hat
- Zerlegung der Länge der totalen quadrierten Abweichungen der Beobachtungswerte $\mathbf{y}$ um deren Mittel $\bar{\mathbf{y}}$ in

$$||\mathbf{y} -  \bar{\mathbf{y}}||^2 = ||\hat{\mathbf{y}} - \bar{\mathbf{y}}||^2 + ||\mathbf{y} - \hat{\mathbf{y}}||^2$$

wobei: $||\hat{\mathbf{y}} - \bar{\mathbf{y}}||^2$ der Länge der quadrierten Abweichungen der gefitteten Werte ($\hat{\mathbf{y}} = \mathbf{X}\hat{\mathbf{\beta}}$) um das globale Mittel ($\bar{\mathbf{y}} = \mathbf{1} * 1/n\sum_{i=1}^ny_i$) und $\mathbf{r} = \mathbf{y} - \hat{\mathbf{y}}$ den Residuen entspricht


## Geometrische Begründung

```{r AnovaDecompositionPlot, echo=FALSE, results='asis'}
rcoursetools::insertOdgAsPdf(psOdgFileStem = "AnovaDecomposition", pnPaperWidthScale = 0.8)
```


## Zerlegung als Varianzanalyse (ANOVA)
- ANOVA Tabelle sieht wie folgt aus

\begin{tabular}{lccc}
            &  sums of squares  &  degrees of freedom  &  mean square \\
regression  &  $||\hat{\mathbf{y}} - \bar{\mathbf{y}}||^2$  &  $p-1$  &  $||\hat{\mathbf{y}} - \bar{\mathbf{y}}||^2 / (p-1)$ \\ 
error       &  $||\mathbf{y} - \hat{\mathbf{y}}||^2$        &  $n-p$  &  $||\mathbf{y} - \hat{\mathbf{y}}||^2 / (n-p)$\\
\hline
total       &  $||\mathbf{y} -  \bar{\mathbf{y}}||^2$       &  $n-1$  &  \\
\end{tabular}

\vspace{2ex}
- Relevante Teststatistik lautet

$$F = \frac{||\hat{\mathbf{y}} - \bar{\mathbf{y}}||^2 / (p-1)}{||\mathbf{y} - \hat{\mathbf{y}}||^2 / (n-p)} \sim F_{p-1,n-p}$$ 

\vspace{2ex}
unter der globalen Nullhypothese $H_0: \beta_j = 0$ für alle $j$


## Bestimmtheitsmass des Modells
- Nützliche Grösse für die Qualität eines Modells ist das Bestimmtheitsmass (coefficient of determination)

$$ R^2 = \frac{||\hat{\mathbf{y}} - \bar{\mathbf{y}}||^2}{||\mathbf{y} -  \bar{\mathbf{y}}||^2}$$

diese sagt aus, wieviel der totalen Variation von $\mathbf{y}$ um $\bar{\mathbf{y}}$ durch die Regression erkärt wird.


##  Vertrauensintervall der Schätzung
- Basierend auf der Teststatistik des t-Tests

$$T_j = \frac{\hat{\beta}_j}{\sqrt{\hat{\sigma}^2(\mathbf{X}^T\mathbf{X})^{-1}_{jj}}} \sim t_{n-p}$$

- Vertrauensintervall für den unbekannten Parameter $\beta_j$ als 

$$\hat{\beta}_j \pm \sqrt{\hat{\sigma}^2(\mathbf{X}^T\mathbf{X})^{-1}_{jj}} * t_{n-p, 1-\alpha/2}$$

$\rightarrow$ somit beinhaltet das Intervall zwischen den angegebenen Grenzen den wahren Wert mit Wahrscheinlichkeit $1-\alpha$, wobei $t_{n-p, 1-\alpha/2}$ das $1-\alpha/2$ Quantil der Verteilung $t_{n-p}$ darstellt


## Vertrauensintervall im Bild

```{r ConfidenceInterval, echo=FALSE, results='asis'}
rcoursetools::insertOdgAsPdf(psOdgFileStem = "ConfidenceInterval", pnPaperWidthScale = 0.8)
```


## R Output

```{r LinModResults, echo=FALSE, results='asis'}
rcoursetools::insertOdgAsPdf(psOdgFileStem = "LinModResults", pnPaperWidthScale = 0.7)
```


## R Output Bedeutung

1. Funktionsaufruf mit welchem das Resultatobjekt erzeugt wurde. Wichtig, falls Resultate als R-objekt (.rda) gespeichert werden
2. Verteilung der Residuen aufgrund der Quantile
3. Schätzwert und Schätzfehler für die Paramter $\beta_j$ zu jeder erklärenden Variablen. Werte der t-Teststatistik
4. Schätzung der Rest-Standardabweichung $\sigma$.  Zusätzliche Modellinformationen, wie F-Teststatistik, $R^2$ und das um Anzahl erklärende Variablen korrigierte $R^2$, wobei

$$\bar{R}^2 = R^2 - (1-R^2)\frac{p-1}{n-p} $$


## Überprüfung der Modellannahmen anhand Analyse der Residuen

- Residuen $r_i = y_i - \hat{y}_i$ als Approximation der unbekannten Fehler $\epsilon_i$ bei der Überprüfung der Modellannahmen verwenden
- __Tukey-Anscombe__ Plot: zeigt Residuen $r_i$ versus gefittete Werte $\hat{y}_i$. Dieser sollte keine erkennbaren Muster aufweisen


```{r TukeyAnscombNoViolation, echo=FALSE, results='asis'}
rcoursetools::insertOdgAsPdf(psOdgFileStem = "TukeyAnscombNoViolation", pnPaperWidthScale = 0.5)
```


## Probleme bei Modellannahmen
Folgende Plots deuten auf Probleme hin

```{r TukeyAnscombProblem, echo=FALSE, results='asis'}
rcoursetools::insertOdgAsPdf(psOdgFileStem = "TukeyAnscombProblem", pnPaperWidthScale = 0.8)
```


## Tukey-Anscombe Plot in R

```{r TukeyAnscombeRcmd, echo = TRUE, eval=FALSE}
data(anscombe)
reg <- lm(y1 ~ x1, data = anscombe)
plot(fitted(reg), resid(reg))
```


## Tukey-Anscombe Plot - Das Resultat


\setkeys{Gin}{width=0.8\paperwidth}
```{r TukeyAnscombeResult, echo=FALSE, results='asis'}
<<TukeyAnscombeRcmd>>
```
\setkeys{Gin}{width=1.1\paperwidth,height=1.1\textheight,keepaspectratio}


## QQ (quantile-quantile) Plot

- Überprüfung der Verteilung der Zufallsvariablen (Zielgrösse und Residuen)
- Empirische Verteilung der Residuen (y-Achse) wird gegen theoretische Quantile der Normalverteilung (x-Achse) aufgezeichnet
- Falls Normalverteilung zutrifft, dann liegen alle Punkte auf einer Linie


## In R:

\setkeys{Gin}{width=0.8\paperwidth}
```{r QQPlot, echo=TRUE, results='asis'}
qqnorm(anscombe$y1)
qqline(anscombe$y1)
```
\setkeys{Gin}{width=1.1\paperwidth,height=1.1\textheight,keepaspectratio}


## Probleme mit Verteilung

```{r QQPlotProblems, echo=FALSE, results='asis'}
rcoursetools::insertOdgAsPdf(psOdgFileStem = "QQPlotProblems", pnPaperWidthScale = 0.8)
```

## Quellen

Tukey-Anscombe Plots und QQ-Plots stammen aus dem Skript: 

\begin{quote}
Computational Statistics\\
Peter B\"uhlmann and Martin M\"achler\\
Seminar f\"ur Statistik ETH Z\"urich\\
Version of January 31, 2014
\end{quote}
